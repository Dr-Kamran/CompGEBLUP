---
title: "CompGEBLUP User Guide"
author: "Muhammad Kamran"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{CompGEBLUP User Guide}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
 collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  warning = FALSE,
  message = FALSE
)
```

# Introduction

**CompGEBLUP** (Comprehensive Genomic Prediction with GBLUP) is an R package for genomic selection and prediction in plant and animal breeding. It implements seven genomic prediction models with varying complexity, from simple additive models to reaction norm and mixed kernel models. Version 2.3.1 features a fully corrected REML engine with exact log-likelihood computation, custom effect support for user-defined kernels, and high-level workflow functions.

## Key Features

- **Independent mixed model engine** - Self-contained REML implementation
- **Full trace-corrected EM-REML** - Unbiased variance component estimation
- **Exact REML log-likelihood** - Reliable convergence monitoring
- **EMMA-style efficient REML** - O(n) per iteration for single random effect models
- **C++ acceleration** - RcppArmadillo backend for 3-10x speedup
- **Multiple genetic effects** - Additive, dominance, and epistatic effects
- **G×E interaction modeling** - Capture genotype-by-environment interactions
- **Custom kernels** - Reaction norm, combined, RKHS, or any user-defined kernel
- **Per-matrix ridge** - Differential regularisation via `ridge_per_matrix`
- **Two-stage workflow** - `compute_two_stage_blues()` for tester-adjusted BLUEs
- **QTL-aware GBLUP** - Major QTL separation for improved prediction
- **Cross-validation** - CV0, CV1, CV2 schemes; `run_cv_battery()` for systematic comparison
- **Fast GWAS** - Efficient genome-wide association with population structure control
- **Multi-trait analysis** - Genetic correlations and selection indices
- **Sparse matrix support** - Memory-efficient for large datasets

## Installation

```{r install, eval=FALSE}
# Install from GitHub
devtools::install_github("Dr-Kamran/CompGEBLUP")
```

```{r load}
library(CompGEBLUP)
```

# Input Data Formats and Structures

## Overview

CompGEBLUP uses the **GBLUPData** S4 class as the primary data container. This object stores genotype data, phenotype data, minor allele frequencies (MAF), and optional metadata in a standardized format that ensures data integrity and compatibility across all package functions.

## GBLUPData Object Structure

The GBLUPData class contains four slots:

| Slot | Type | Description |
|------|------|-------------|
| `genotypes` | matrix | Genotype matrix (individuals × markers) |
| `phenotypes` | data.frame | Phenotype data with GID, ENV, trait columns |
| `maf` | numeric | Minor allele frequency vector |
| `metadata` | list | Optional metadata (marker positions, etc.) |

## Genotype Data Requirements

### Format Specification

**Matrix dimensions:** `n_individuals × n_markers`

**Coding scheme:** Genotypes must be coded as **-1, 0, 1** representing:

| Code | Genotype | Description |
|------|----------|-------------|
| `-1` | aa | Homozygous (0 copies of reference allele) |
| `0` | Aa | Heterozygous (1 copy of reference allele) |
| `1` | AA | Homozygous (2 copies of reference allele) |

**Note:** This coding is derived from the standard 0/1/2 coding by subtracting 1: `coded = original - 1`

**Row names:** Individual/genotype IDs (required)

**Column names:** Marker/SNP names (required)

**Missing data:** `NA` values are allowed but should be minimized (< 5% recommended)

### Example Genotype Matrix

```{r example-genotypes-show, echo=FALSE}
example_geno <- matrix(
  c(-1, 0, 1, 0, -1,
     0, 1, 0, -1, 1,
     1, 0, -1, 1, 0,
     0, -1, 1, 0, 1),
  nrow = 4, byrow = TRUE,
  dimnames = list(
    c("ID1", "ID2", "ID3", "ID4"),
    c("SNP1", "SNP2", "SNP3", "SNP4", "SNP5")
  )
)
print(example_geno)
```

## Phenotype Data Requirements

### Required Columns

The phenotype data frame **must** contain exactly three columns with these names:
| Column | Type | Description |
|--------|-----------|---------------------------------------|
| `GID` | character | Genotype/individual ID (must match genotype row names) |
| `ENV` | character | Environment identifier (use "E1" for single environment) |
| `trait` | numeric | Phenotypic trait value |

### Format Details

- **Multiple environments:** Each individual can have observations in multiple environments (replicated rows)
- **Missing values:** Use `NA` for missing phenotypes (handled internally)
- **Single trait:** Only one trait column allowed; use multi-trait functions for multiple traits
- **Order:** Rows can be in any order

### Example Phenotype Data

```{r example-phenotypes-show, echo=FALSE}
example_pheno <- data.frame(
  GID = c("ID1", "ID1", "ID1", "ID2", "ID2", "ID2"),
  ENV = c("E1", "E2", "E3", "E1", "E2", "E3"),
  trait = c(102.3, 98.7, 105.1, 89.4, 91.2, 88.8)
)
print(example_pheno)
```

## Minor Allele Frequency (MAF)

- **Format:** Numeric vector
- **Length:** Must equal the number of markers (columns in genotype matrix)
- **Range:** Values between 0 and 0.5
- **Calculation:** `maf <- pmin(p, 1-p)` where `p <- colMeans(genotypes + 1) / 2`

## Creating GBLUPData Objects

### Method 1: Using Simulation Functions (Recommended for Testing)
```{r create-simulated}
# Simulate genotype and phenotype data
set.seed(123)
gdata <- simulate_genotypes(n_ind = 100, n_snp = 500)
gdata <- simulate_phenotypes(gdata, n_env = 3, h2 = 0.6, n_qtl = 20)

# View the object
gdata
```

### Method 2: From Existing Data Matrices

```{r create-from-matrices, eval=FALSE}
# Assume you have:
# M = genotype matrix (coded as -1, 0, 1)
# pheno = data frame with GID, ENV, trait columns

# Calculate MAF
p <- colMeans(M + 1, na.rm = TRUE) / 2
maf <- pmin(p, 1 - p)

# Create GBLUPData object
gdata <- new("GBLUPData",
             genotypes = M,
             phenotypes = pheno,
             maf = maf,
             metadata = list())
```

### Data Validation

The GBLUPData class automatically validates:

1. **Phenotype columns:** Checks for required GID, ENV, trait columns
2. **MAF length:** Ensures MAF vector matches number of markers
3. **Genotype coding:** Verifies all values are -1, 0, or 1 (excluding NA)

If validation fails, you'll receive an informative error message.

## Converting from Common Formats

### From 0/1/2 Coding

```{r convert-012, eval=FALSE}
# Original format: 0, 1, 2 (minor allele count)
M_012 <- as.matrix(read.csv("genotypes.csv", row.names = 1))

# Convert to -1/0/1 coding
M <- M_012 - 1

# Calculate MAF
p <- colMeans(M + 1, na.rm = TRUE) / 2
maf <- pmin(p, 1 - p)
```

### From PLINK Files

```{r convert-plink, eval=FALSE}
# Using snpStats package
library(snpStats)

# Read PLINK files
plink <- read.plink("genotypes.bed", "genotypes.bim", "genotypes.fam")

# Convert to numeric matrix (0/1/2)
M_012 <- as(plink$genotypes, "numeric")

# Convert to -1/0/1
M <- M_012 - 1

# Handle missing values (snpStats uses NA)
# Simple mean imputation
for (j in 1:ncol(M)) {
  missing <- is.na(M[, j])
  if (any(missing)) {
    M[missing, j] <- mean(M[, j], na.rm = TRUE)
  }
}
```

## Data Quality Control

```{r qc-example, eval=FALSE}
# Check data compatibility
check_data_compatibility(gdata, K_matrices)

# Summary statistics
summary_gblup_data(gdata)
```

## Data Requirements by Model

| Model | Min Individuals | Min Markers | Min Environments | Notes |
|-------|----------------|-------------|------------------|-------|
| Model 1 (A) | 50 | 500 | 1 | Basic additive model |
| Model 2 (A+D) | 100 | 500 | 1 | Requires heterozygotes |
| Model 3 (A+ENV+AE) | 50 | 500 | 2+ | Multiple environments |
| Model 4 (Full G×E) | 100 | 1000 | 2+ | Full G×E model |
| Model 5 (Epistasis) | 200+ | 1000+ | 2+ | Large samples needed |

# Quick Start

## Simulate Data

```{r simulate-data}
# Simulate genotype data
set.seed(123)
gdata <- simulate_genotypes(n_ind = 200, n_snp = 1000)

# Simulate phenotypes with moderate heritability
gdata <- simulate_phenotypes(
  gdata,
  n_env = 3,
  h2 = 0.6,
  n_qtl = 50,
  include_dominance = TRUE,
  include_gxe = TRUE
)

# View the data structure
gdata
```

## Calculate Relationship Matrices

```{r calc-matrices}
# Calculate additive relationship matrix
K <- calc_relationship_matrices(gdata, matrices = "A")

# View matrix properties
cat("A matrix dimensions:", dim(K$A), "\n")
cat("A matrix diagonal range:", round(range(diag(K$A)), 3), "\n")
```

# The Five Core Models

CompGEBLUP implements five pre-configured models of increasing complexity:

| Model | Effects | Description |
|-------|---------|-------------|
| Model 1 | A | Additive effects only (baseline) |
| Model 2 | A + D | Additive + Dominance |
| Model 3 | A + ENV + AE | Additive + Environment + A×E interaction |
| Model 4 | A + D + ENV + AE + DE | Full G×E with dominance |
| Model 5 | A + D + ENV + AE + AA | Includes epistasis |

## Model 1: Additive Effects (A)

The baseline model with only additive genetic effects.

```{r model1}
model1 <- fit_model1_A(gdata, verbose = FALSE)
model1
```

## Model 2: Additive + Dominance (A + D)

Includes both additive and dominance genetic effects. Uses differential ridge:
D matrix gets stronger regularisation (0.05) due to near-zero eigenvalues.

```{r model2}
model2 <- fit_model2_AD(gdata, verbose = FALSE)
model2
```

## Model 3: Additive G×E (A + ENV + AE)

Includes additive effects and additive-by-environment interactions.
For real data with confounders (tester, block), use two-stage BLUEs:

```{r model3}
model3 <- fit_model3_AE(gdata, verbose = FALSE)
model3
```

### Two-Stage Workflow

When phenotypic data contains confounding effects (tester, block, replication),
use `compute_two_stage_blues()` to absorb these in Stage 1 before fitting
GxE models in Stage 2:

```{r two-stage, eval=FALSE}
# Stage 1: Absorb tester effects within each environment
gdata_2stage <- compute_two_stage_blues(gdata, fixed = ~ TESTER)

# Stage 2: Fit GxE model on tester-adjusted BLUEs
model3_2s <- fit_model3_AE(gdata_2stage, verbose = FALSE)
```

## Model 3R: Reaction Norm (Finlay-Wilkinson)

Captures G×E from heterogeneous environmental sensitivity using a
Finlay-Wilkinson random regression kernel. Each genotype gets a slope
representing its response to environmental quality.

```{r model3r, eval=FALSE}
# Build FW reaction norm kernel
K <- calc_relationship_matrices(gdata, matrices = "A")
K_rn <- build_reaction_norm_kernel(gdata, K$A)

# Fit as custom effect
model3R <- fit_model3R_reaction_norm(gdata, A = K$A, fixed = ~ TESTER)
```

## Model 4: A + D + ENV + AE (GxE with Dominance)

DE is dropped by default (causes overfitting in hybrid data). Enable with `include_DE = TRUE`.

```{r model4}
model4 <- fit_model4_ADE(gdata, verbose = FALSE)
model4
```

## Model 5: A + ENV + AE + AA (Epistasis)

D is dropped by default (boundary estimate when epistasis is present). Enable with `include_D = TRUE`.

```{r model5, warning=FALSE}
# Epistasis model - may require large datasets for stable estimation
model5 <- tryCatch({
  fit_model5_ADAA(gdata, verbose = FALSE)
}, error = function(e) {
  message("Note: Using Model 4 as fallback (epistasis requires larger datasets)")
  fit_model4_ADE(gdata, verbose = FALSE)
})
model5
```

## Model 5C: Mixed Kernel (Trace-Scaled A + AA)

Combines additive and epistatic effects into a single trace-normalised kernel,
weighted by variance components from Model 5.

```{r model5c, eval=FALSE}
vc5 <- get_varcomp(model5)
sig2_A  <- vc5$Variance[vc5$Component == "A"]
sig2_AA <- vc5$Variance[vc5$Component == "AA"]

model5C <- fit_model5C_mixed_kernel(
  gdata, A = K$A, AA = K$AA,
  varcomp = c(A = sig2_A, AA = sig2_AA)
)
```

## Custom Effects

Any user-defined relationship matrix can be used as a random effect. The
package auto-detects whether a custom kernel is GID-level (n_gid × n_gid)
or GID.ENV-level (n_gid*n_env × n_gid*n_env):
  
```{r custom-effects, eval=FALSE}
# Example: RKHS kernel
K_rkhs <- exp(-as.matrix(dist(gdata@genotypes))^2 / median(dist(gdata@genotypes))^2)
rownames(K_rkhs) <- colnames(K_rkhs) <- rownames(gdata@genotypes)

model_custom <- fit_gblup(gdata,
  K_matrices = list(A = K$A, RKHS = K_rkhs),
  effects = c("A", "RKHS"),
  ridge_per_matrix = c(A = 0.001, RKHS = 0.01),
  use.emma = FALSE, verbose = FALSE
)
```

# Model Comparison

Compare prediction accuracy across models:

```{r compare-models}
model_list <- list(
  "Model 1 (A)" = model1,
  "Model 2 (A+D)" = model2,
  "Model 3 (A+ENV+AE)" = model3,
  "Model 4 (A+D+ENV+AE)" = model4
)

comparison <- compare_models(model_list)
print(comparison[, c("Model", "Predictive_Ability", "AIC", "BIC", "Converged")])
```

## Compile Detailed Results

Use `compile_results()` for a publication-ready summary:

```{r compile, eval=FALSE}
results <- compile_results(model_list)
print(results$summary)
print(results$varcomp)
```

# Working with Results

## Extract GEBVs

```{r extract-gebv}
# Extract genomic estimated breeding values
gebv <- extract_gebv(model1)
head(gebv)

# Summary statistics
cat("\nGEBV Summary:\n")
cat("  Mean:", round(mean(gebv$GEBV, na.rm = TRUE), 3), "\n")
cat("  SD:", round(sd(gebv$GEBV, na.rm = TRUE), 3), "\n")
cat("  Range:", paste(round(range(gebv$GEBV, na.rm = TRUE), 3), collapse = " to "), "\n")
```

## Extract Variance Components

```{r extract-varcomp}
# Get variance components
varcomp <- extract_varcomp(model1)
print(varcomp)

# Calculate heritability
h2 <- heritability(model1)
cat("\nHeritability estimates:\n")
cat("  Narrow-sense (h2):", round(h2["h2"], 3), "\n")
cat("  Broad-sense (H2):", round(h2["H2"], 3), "\n")
```

## Visualization

```{r viz-gebv, fig.width=7, fig.height=5}
# GEBV distribution
plot_gebv(model1, type = "histogram")
```

```{r viz-obs-pred, fig.width=7, fig.height=5}
# Observed vs Predicted
plot_obs_vs_pred(model1)
```

```{r viz-varcomp, fig.width=7, fig.height=5}
# Variance components
plot_variance_components(model1, type = "barplot")
```

# Cross-Validation

## CV Schemes

CompGEBLUP supports three cross-validation schemes:

| Scheme | Description | Use Case | Typical Accuracy |
|--------|-------------|----------|------------------|
| CV1 | Random k-fold (individuals) | Predict NEW genotypes | Lower (0.2-0.5) |
| CV2 | Leave-one-environment-out | Predict in NEW environments | Higher (0.5-0.8) |
| CV0 | Within-environment k-fold | Environment-specific accuracy | Variable |

### Why CV2 > CV1?

**CV1 (new genotypes):** 
- Predicts individuals with NO phenotypic data
- Must rely entirely on marker similarity
- Harder task → lower accuracy

**CV2 (new environments):**
- Predicts known individuals in new environments
- Can use existing phenotypes from other environments
- Easier task → higher accuracy

```
            Environment
            E1    E2    E3
         ┌─────┬─────┬─────┐
    G1   │  ●  │  ●  │  ?  │  ← CV2: Predict G1 in E3 (knows G1 from E1,E2)
         │     │     │     │
    G2   │  ●  │  ●  │  ?  │
         ├─────┼─────┼─────┤
    G3   │  ?  │  ?  │  ?  │  ← CV1: Predict G3 (never seen!)
         └─────┴─────┴─────┘
```

## Running Cross-Validation

### Strict vs Fast CV

CompGEBLUP offers two cross-validation modes:

| Mode | Parameter | Description | Speed |
|------|-----------|-------------|-------|
| **Strict (default)** | `recompute_K = TRUE` | K matrix recomputed per fold using only training genotypes. **No data leakage.** | Slower |
| **Fast** | `recompute_K = FALSE` | K matrix computed once from all individuals. Minor genotype leakage. | Faster |

**Why this matters:** In standard practice, most packages compute K from all individuals including test set. While phenotypes are properly masked, test genotypes still influence the K matrix - a subtle form of information leakage that can inflate accuracy estimates.

```{r cv-example}
# Create smaller dataset for faster CV
set.seed(456)
cv_data <- simulate_genotypes(n_ind = 80, n_snp = 300)
cv_data <- simulate_phenotypes(cv_data, n_env = 3, h2 = 0.65, n_qtl = 30)
K_cv <- calc_relationship_matrices(cv_data, matrices = "A")

# Strict CV (default) - K recomputed per fold, no data leakage
cv_result <- cv_gblup(
  cv_data, 
  K_cv, 
  effects = "A",
  scheme = "CV1",
  n_folds = 5,
  n_reps = 2,
  recompute_K = TRUE,  # Default - strict mode
  verbose = FALSE
)

print(cv_result)
```

### CV Battery

Use `run_cv_battery()` to systematically compare multiple models across CV schemes:

```{r cv-battery, eval=FALSE}
K_cv <- calc_relationship_matrices(cv_data, matrices = c("A", "D", "AA"))

cv_results <- run_cv_battery(
  gdata = cv_data, K_matrices = K_cv,
  models = list(
    M1 = list(effects = "A"),
    M2 = list(effects = c("A", "D")),
    M3 = list(effects = c("A", "ENV", "AE")),
    M5 = list(effects = c("A", "ENV", "AE", "AA"))
  ),
  schemes = c("CV1", "CV2"),
  n_folds = 5, n_reps = 3,
  ridge_per_matrix = c(A = 0.001, D = 0.05, AA = 0.05, AE = 0.05)
)

print(cv_results)
```

```{r cv-fast, eval=FALSE}
# Fast CV - K computed once (minor genotype leakage)
# Use when computational time is critical
cv_result_fast <- cv_gblup(
  cv_data, 
  K_cv, 
  effects = "A",
  scheme = "CV1",
  n_folds = 5,
  recompute_K = FALSE,  # Fast mode
  verbose = FALSE
)
```

## CV Metrics

```{r cv-metrics}
# Overall summary
cv_summary <- get_cv_metrics(cv_result, by_fold = FALSE)
print(cv_summary)

# By-fold details
cv_by_fold <- get_cv_metrics(cv_result, by_fold = TRUE)
print(cv_by_fold)
```

## CV Visualization

```{r cv-plot, fig.width=7, fig.height=5}
# Scatter plot of predictions
plot_cv_results(cv_result, type = "scatter")
```

```{r cv-boxplot, fig.width=7, fig.height=5}
# Accuracy by fold
plot_cv_results(cv_result, type = "boxplot")
```

# Genome-Wide Association Study (GWAS)

## Running GWAS

```{r gwas-run}
# Create data for GWAS
set.seed(789)
gwas_data <- simulate_genotypes(n_ind = 150, n_snp = 500)
gwas_data <- simulate_phenotypes(gwas_data, n_env = 1, h2 = 0.7, n_qtl = 10)
K_gwas <- calc_relationship_matrices(gwas_data, matrices = "A")

# Run GWAS with mixed model
gwas_result <- gwas(
  gwas_data,
  K_matrices = K_gwas,
  effects = "A",
  min.MAF = 0.05,
  P3D = TRUE,
  verbose = FALSE
)

print(gwas_result)
```

## GWAS Results

```{r gwas-results}
# Top markers
top_markers <- get_top_markers(gwas_result, n = 10)
print(top_markers[, c("marker", "beta", "p_value", "log10p")])

# Significant markers (Bonferroni)
sig_markers <- get_significant_markers(gwas_result, method = "bonferroni")
cat("\nSignificant markers (Bonferroni):", nrow(sig_markers), "\n")
```

## GWAS Plots

```{r gwas-manhattan, fig.width=7, fig.height=5}
# Manhattan plot
plot_manhattan(gwas_result)
```

```{r gwas-qq, fig.width=7, fig.height=5}
# QQ plot
plot_qq(gwas_result)
```

# Multi-Trait Analysis

```{r multi-trait-setup}
# Add second trait
mt_data <- gdata
mt_data@phenotypes$trait2 <- mt_data@phenotypes$trait * 0.7 + 
  rnorm(nrow(mt_data@phenotypes), 0, 8)
```

```{r multi-trait-fit, warning=FALSE}
# Fit multi-trait model
K_mt <- calc_relationship_matrices(mt_data, matrices = "A")

mt_model <- fit_multi_trait(
  mt_data,
  traits = c("trait", "trait2"),
  K_matrices = K_mt,
  effects = "A",
  genetic_model = "diagonal",
  verbose = FALSE
)

# Summary
summary_multi_trait(mt_model)
```

```{r selection-index, eval=FALSE}
# Calculate selection index
weights <- c(trait = 0.6, trait2 = 0.4)
index <- selection_index(mt_model, weights)
head(index)
```

# QTL-Aware GBLUP

CompGEBLUP supports separating major QTL effects (fixed) from polygenic background effects (random). This can improve prediction accuracy when major genes are known.

## Concept

The standard GBLUP model:
$$y = X\mu + Za + \epsilon$$

becomes the QTL-aware model:
$$y = X\mu + X_a\beta_{QTL} + Z\tilde{a} + \epsilon$$

Where:
- $X_a$ = QTL marker genotypes (fixed effects)
- $\beta_{QTL}$ = estimated QTL effects
- $\tilde{a}$ = polygenic effects with reduced K matrix (excludes QTL markers)

## Method 1: Automatic QTL Detection Pipeline

```{r qtl-auto, eval=FALSE}
# One-step pipeline: GWAS → detect QTLs → fit model
result <- fit_gblup_auto_qtl(
  gdata,
  gwas_threshold = 0.05,
  gwas_method = "bonferroni",
  max_qtl = 20,
  effects = c("A", "ENV"),
  verbose = TRUE
)

# View detected QTLs
print(result$qtl_markers)

# View QTL effects
print(result$qtl_effects)

# Access the model
model <- result$model
```

## Method 2: Manual QTL Specification

```{r qtl-manual, eval=FALSE}
# If you already know your QTLs (from previous GWAS or literature)
M <- gdata@genotypes
qtl_names <- c("SNP_100", "SNP_250", "SNP_500")  # Your known QTLs

# Build QTL-aware matrices
qtl_mats <- build_qtl_aware_matrices(M, qtl_markers = qtl_names)

# View what was created
cat("Markers in polygenic K:", qtl_mats$n_non_qtl, "\n")
cat("QTL markers as fixed:", qtl_mats$n_qtl, "\n")

# Fit model
model <- fit_gblup_qtl(
  gdata, 
  Ka = qtl_mats$Ka,    # Reduced K matrix
  Xa = qtl_mats$Xa,    # QTL genotypes for fixed effects
  effects = c("A", "ENV"),
  verbose = TRUE
)
```

## Method 3: From GWAS Results

```{r qtl-gwas, eval=FALSE}
# Step 1: Run GWAS
K_full <- calc_relationship_matrices(gdata, matrices = "A")
gwas_res <- gwas(gdata, K_matrices = K_full, verbose = FALSE)

# Step 2: Get significant markers
sig_markers <- get_significant_markers(gwas_res, method = "bonferroni")
cat("Found", nrow(sig_markers), "significant QTLs\n")

# Step 3: Build QTL-aware matrices
M <- gdata@genotypes
qtl_mats <- build_qtl_aware_matrices(M, qtl_markers = sig_markers$marker)

# Step 4: Fit QTL-aware model
model <- fit_gblup_qtl(gdata, Ka = qtl_mats$Ka, Xa = qtl_mats$Xa)

# Step 5: Extract results
qtl_effects <- get_qtl_effects(model)
print(qtl_effects)

# GEBV breakdown (polygenic vs QTL)
components <- get_gebv_components(model)
head(components)
```

## Cross-Validation with QTL Model

```{r cv-qtl, eval=FALSE}
# CV for QTL-aware model
cv_qtl <- cv_gblup_qtl(
  gdata,
  qtl_markers = sig_markers$marker,
  scheme = "CV1",
  n_folds = 5,
  n_reps = 2,
  effects = c("A", "ENV"),
  verbose = TRUE
)

print(cv_qtl)
```

## When to Use QTL-Aware Models

| Scenario | Recommendation |
|----------|----------------|
| Oligogenic traits (few major genes) | ✅ Use QTL-aware |
| Known disease resistance genes | ✅ Use QTL-aware |
| GWAS finds significant associations | ✅ Use QTL-aware |
| Purely polygenic traits | ❌ Standard GBLUP sufficient |
| Small sample size (< 200) | ❌ May overfit with QTL model |

# Custom Model Fitting

For advanced users who want to specify custom model configurations:

```{r custom-model}
# Calculate specific matrices
K_custom <- calc_relationship_matrices(
  gdata, 
  matrices = c("A", "D"),
  method = "VanRaden",
  min.MAF = 0.05,
  ridge = 0.001
)

# Fit custom model
custom_model <- fit_gblup(
  gdata,
  K_matrices = K_custom,
  effects = c("A", "D", "ENV"),
  ridge = 0.001,
  nIters = 50,
  tolParConvLL = 1e-4,
  verbose = FALSE
)

summary(custom_model)
```

# Performance Optimization

CompGEBLUP includes several optimizations for large datasets.

## EMMA Algorithm

For single random effect models, CompGEBLUP uses the EMMA (Efficient Mixed-Model Association) algorithm which is O(n) per iteration instead of O(n³):

```{r emma-example, eval=FALSE}
# EMMA is used automatically for single random effect models
model <- fit_gblup(gdata, K, effects = "A")  # Uses EMMA

# For multiple random effects, uses AI-REML
model <- fit_gblup(gdata, K, effects = c("A", "ENV", "AE"))  # Uses AI-REML
```

## C++ Acceleration

All matrix operations use RcppArmadillo by default:

```{r cpp-example, eval=FALSE}
# C++ is enabled by default
K <- calc_relationship_matrices(gdata, matrices = "A")

# Disable C++ for debugging (slower)
K <- calc_relationship_matrices(gdata, matrices = "A", use.cpp = FALSE)
```

## Sparse Matrices

For large datasets, enable sparse matrix support to reduce memory usage by ~90%:
  
```{r sparse-example, eval=FALSE}
# Enable sparse matrices for design matrices
model <- fit_gblup(gdata, K, effects = "A", use.sparse = TRUE)
```

## Performance Comparison

| Dataset Size | Standard | With C++ | With EMMA | Speedup |
|--------------|----------|----------|-----------|---------|
| n=500, p=1000 | 10s | 3s | 1s | 10x |
| n=1000, p=5000 | 120s | 40s | 8s | 15x |
| n=2000, p=10000 | 600s+ | 200s | 30s | 20x |

# Troubleshooting

## Common Issues and Solutions

### Model Fails to Converge

```{r troubleshoot-converge, eval=FALSE}
# Solution 1: Increase ridge parameter
model <- fit_gblup(gdata, K, effects = "A", ridge = 0.01)

# Solution 2: Reduce model complexity
model <- fit_model1_A(gdata)  # Start with simplest model

# Solution 3: Increase iterations
model <- fit_gblup(gdata, K, effects = "A", nIters = 100)
```

### Singular Matrix Errors

```{r troubleshoot-singular, eval=FALSE}
# Check for issues
diagnose_model(model)

# Solutions:
# 1. Increase ridge parameter
# 2. Filter markers more stringently (higher MAF)
# 3. Remove highly correlated individuals
# 4. Use simpler model
```

### Memory Issues

```{r troubleshoot-memory, eval=FALSE}
# Reduce marker set
K <- calc_relationship_matrices(gdata, matrices = "A", 
                                 max.memory.gb = 4)  # Set memory limit

# Use CV0 instead of CV1 for large datasets
cv <- cv_gblup(gdata, K, scheme = "CV0", n_folds = 3)
```

## Diagnostics

```{r diagnostics}
# Run model diagnostics
diagnose_model(model1)
```

# Best Practices

## Recommendations

1. **Start simple:** Begin with Model 1 (A) as baseline
2. **Add complexity gradually:** Compare AIC/BIC as you add effects
3. **Use cross-validation:** Always validate with CV before interpreting results
4. **Check convergence:** Ensure models converged before using results
5. **Consider sample size:** More complex models need larger datasets

## Minimum Data Requirements

- **Individuals:** At least 50 for simple models, 200+ for epistasis
- **Markers:** At least 500 SNPs, preferably 1,000+
- **Environments:** At least 3 for reliable G×E estimation
- **Heritability:** Low h² traits need larger sample sizes

# Session Information

```{r session-info}
sessionInfo()
```

# References

1. VanRaden PM (2008). Efficient methods to compute genomic predictions. *Journal of Dairy Science* 91:4414-4423.

2. Vitezica ZG et al. (2013). On the additive and dominant variance and covariance of individuals within the genomic selection scope. *Genetics* 195:1223-1230.

3. Su G et al. (2012). Estimating additive and non-additive genetic variances and predicting genetic merits using genome-wide dense single nucleotide polymorphism markers. *PLoS ONE* 7:e45293.

4. Kang HM et al. (2008). Efficient control of population structure in model organism association mapping. *Genetics* 178:1709-1723.

# Getting Help

- **Package documentation:** `help(package = "CompGEBLUP")`
- **Function help:** `?fit_gblup`, `?cv_gblup`, etc.
- **GitHub repository:** https://github.com/Dr-Kamran/CompGEBLUP
- **Report issues:** https://github.com/Dr-Kamran/CompGEBLUP/issues